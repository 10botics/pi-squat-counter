{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efbc1fe-bc44-45b8-bcc9-f0641ffb08c2",
   "metadata": {},
   "source": [
    "# Posture detection using tensorflow判斷人體姿態<br>**Bonus**: Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11decd-28fc-48c4-924a-5e924bd11f06",
   "metadata": {},
   "source": [
    "\n",
    "Although our code for Step 6 can achieve the basic function of counting squats, due to the heavy computation resources needed by Movenet, the operation is too slow, resulting in our counter running less smoothly and responsively.<br>\n",
    "雖然我們Step6的代碼能夠實現深蹲計數的基本功能，但由於Movenet需要大量的計算資源，運行太過緩慢，使得我們的計數器運行不夠流暢和靈敏。<br>\n",
    "<br>\n",
    "The Coral accelerator is a hardware accelerator specifically designed to speed up deep learning inference, and can be used with Raspberry Pi 4. It can greatly improve the model inference speed, making it more smooth to run Movenet on Raspberry Pi 4.<br>\n",
    "Coral accelerator是一種專門設計用於加速深度學習推理的硬體加速器，可以與Raspberry Pi 4一起使用。Coral accelerator可以大大提高模型推理速度，從而使得在Raspberry Pi 4上運行Movenet變得更加流暢。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42c317-1184-4311-945b-655376b9ffdf",
   "metadata": {},
   "source": [
    "##### <hr>First, we import the necessary libraries and redefine some of the functions used before.<br>首先，我們導入所需要的庫，並重新定義一些之前的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c539ab8d-3a41-4c29-9283-0fe78fff0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def putText(frame, text, text_color = (0, 255, 0), text_position = (50, 50)):\n",
    "    # Define the text properties\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_scale = 0.65\n",
    "    text_thickness = 2\n",
    "\n",
    "    # Add text annotation on the frame\n",
    "    cv2.putText(frame, text, text_position, font, text_scale, text_color, text_thickness)\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle\n",
    "\n",
    "def calculate_hip_joint_angle(keypoints_with_scores, keypoint_threshold = 0.2): \n",
    "    \n",
    "    # get the position of keypoints from MoveNet output\n",
    "    a1y, a1x, a1s = keypoints_with_scores[KEYPOINT_DICT[\"left_shoulder\"]]\n",
    "    a2y, a2x, a2s = keypoints_with_scores[KEYPOINT_DICT[\"right_shoulder\"]]\n",
    "    b1y, b1x, b1s = keypoints_with_scores[KEYPOINT_DICT[\"left_hip\"]]\n",
    "    b2y, b2x, b2s = keypoints_with_scores[KEYPOINT_DICT[\"right_hip\"]]\n",
    "    c1y, c1x, c1s = keypoints_with_scores[KEYPOINT_DICT[\"left_knee\"]]\n",
    "    c2y, c2x, c2s = keypoints_with_scores[KEYPOINT_DICT[\"right_knee\"]]\n",
    "\n",
    "    # calculate angle of left and right body respectively\n",
    "    angle1 = calculate_angle( (a1y, a1x), (b1y, b1x), (c1y, c1x) )\n",
    "    angle2 = calculate_angle( (a2y, a2x), (b2y, b2x), (c2y, c2x) )\n",
    "\n",
    "    # if confident score of keypoints are all above threshold, return the midpoint of two angle\n",
    "    # otherwise, return None\n",
    "    if (a1s>keypoint_threshold)*(b1s>keypoint_threshold)*(c1s>keypoint_threshold):\n",
    "        return (angle1 + angle2) / 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def calculate_knee_joint_angle(keypoints_with_scores, keypoint_threshold = 0.2): \n",
    "\n",
    "    # get the position of keypoints from MoveNet output\n",
    "    a1y, a1x, a1s = keypoints_with_scores[KEYPOINT_DICT[\"left_hip\"]]\n",
    "    a2y, a2x, a2s = keypoints_with_scores[KEYPOINT_DICT[\"right_hip\"]]\n",
    "    b1y, b1x, b1s = keypoints_with_scores[KEYPOINT_DICT[\"left_knee\"]]\n",
    "    b2y, b2x, b2s = keypoints_with_scores[KEYPOINT_DICT[\"right_knee\"]]\n",
    "    c1y, c1x, c1s = keypoints_with_scores[KEYPOINT_DICT[\"left_ankle\"]]\n",
    "    c2y, c2x, c2s = keypoints_with_scores[KEYPOINT_DICT[\"right_ankle\"]]\n",
    "\n",
    "    # calculate angle of left and right body respectively\n",
    "    angle1 = calculate_angle( (a1y, a1x), (b1y, b1x), (c1y, c1x) )\n",
    "    angle2 = calculate_angle( (a2y, a2x), (b2y, b2x), (c2y, c2x) )\n",
    "\n",
    "    # if confident score of keypoints are all above threshold, return the midpoint of two angle\n",
    "    # otherwise, return None\n",
    "    if (a1s>keypoint_threshold)*(b1s>keypoint_threshold)*(c1s>keypoint_threshold):\n",
    "        return (angle1 + angle2) / 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "import time\n",
    "\n",
    "def view( button, source=0, rotate=0, process=(lambda x:x)):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    button: An IPywidget button to control the function. The display stops if button.value == True.\n",
    "    source: An optional integer or filename to specify the source of the video stream.\n",
    "    rotate: optional integer. Set to 0 by default (not rotated). Set to 1 will rotate by 90 deg.\n",
    "    process: optional function that processes each frame through process(frame) before displaying.\n",
    "        Set to identity function by default.\n",
    "    \"\"\"\n",
    "    global time_process, start_time\n",
    "    time_process = []\n",
    "    \n",
    "    display_handle=display(\"Please wait...\", display_id=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(source)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        start_time_process = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if button.value==True or not ret:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "            button.value = False\n",
    "            break\n",
    "\n",
    "        #frame = cv2.flip(frame, 1)  # if the camera mirrors your image\n",
    "\n",
    "        # Rotate the frame if rotate==1\n",
    "        if rotate:\n",
    "            frame = cv2.transpose(frame)\n",
    "            frame = cv2.flip(frame, 0)\n",
    "        \n",
    "        frame = process(frame)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(IPython.display.Image(data=frame.tobytes()))\n",
    "\n",
    "        time_process.append(time.time() - start_time_process)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a837fe6-b9d8-4788-b72a-ab24acd19ee8",
   "metadata": {},
   "source": [
    "##### Next, let's try using Python to drive the Coral Accelerator to perform image inference.<br>接下來，讓我們試着用python驅動Coral Accelerator去執行圖片推理<br>\n",
    "After importing the libraries, we defined function `get_result_from_image_with_model`. This function takes an image as input and applies a pre-trained pose detection model to extract the positions of key points on the human body in the image. With this function, we can quickly obtain MoveNet results using the Coral Accelerator by simply providing an image and an interpreter.<br>\n",
    "導入相關庫之後，我們定義了`get_result_from_image_with_model`函數。這個函數需要輸入一張圖像並應用預先訓練的姿勢判斷模型，以提取圖像中人體關鍵點的位置。這個函數讓我們只需給定一張圖像和解釋器，就能夠利用Coral Accelerator快速得出MoveNet結果了。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197d7816-3ee2-4415-bc64-f77f1abbebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      "(17, 3)\n",
      "\n",
      "[[0.32774833 0.589947   0.5694627 ]\n",
      " [0.3113609  0.59814066 0.5694627 ]\n",
      " [0.3113609  0.56536585 0.75382113]\n",
      " [0.31545776 0.5776564  0.36462   ]\n",
      " [0.31545776 0.50391304 0.70056206]\n",
      " [0.41378227 0.5694627  0.5694627 ]\n",
      " [0.4014917  0.43426654 0.43016967]\n",
      " [0.5121068  0.70875573 0.29907033]\n",
      " [0.5121068  0.53259104 0.75382113]\n",
      " [0.42197597 0.6964652  0.49981618]\n",
      " [0.4178791  0.6513998  0.29907033]\n",
      " [0.59814066 0.38920113 0.75382113]\n",
      " [0.6145281  0.2867798  0.70056206]\n",
      " [0.6595935  0.58175325 0.49981618]\n",
      " [0.6800778  0.41378227 0.6350124 ]\n",
      " [0.8398551  0.52030045 0.19664899]\n",
      " [0.9013079  0.33594203 0.43016967]]\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from pycoral.adapters import common\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "\n",
    "interpreter = make_interpreter(\"movenet_single_pose_lightning_ptq_edgetpu.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "_NUM_KEYPOINTS = 17\n",
    "\n",
    "def get_result_from_image_with_model(input, interpreter, output=None):\n",
    "    '''\n",
    "    This function takes an input image and applies a pre-trained pose estimation model \n",
    "    to extract the position of human body keypoints in the image. \n",
    "    The TensorFlow Lite interpreter object is used to run inference on the input image\n",
    "    using the pre-trained model.\n",
    "    If the optional output argument is provided, the function also saves the input image\n",
    "    with the detected keypoints drawn on it to the specified file path.\n",
    "\n",
    "    Args:\n",
    "    input: An input image file path or a numpy array representing an image.\n",
    "    interpreter: A TensorFlow Lite interpreter object.\n",
    "    output (optional): A file path to save the output image with keypoints drawn on it.\n",
    "\n",
    "    Return:\n",
    "    Array of keypoints. Each keypoint is represented as a triplet of [y, x, score].\n",
    "    '''\n",
    "    # load the input image using PIL\n",
    "    if isinstance(input, str):\n",
    "        img = PIL.Image.open(input)\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        img = PIL.Image.fromarray(cv2.cvtColor(input, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # resize the image to model required size\n",
    "    resized_img = img.resize(common.input_size(interpreter), PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "    # load the resized image to interpreter\n",
    "    common.set_input(interpreter, resized_img)\n",
    "\n",
    "    # conduct the inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # reshape and assign the inference result to variable `pose`\n",
    "    keypoints_with_scores = common.output_tensor(interpreter, 0).copy().reshape(_NUM_KEYPOINTS, 3)\n",
    "\n",
    "    # draw the keypoints and save the image (if specified `output`)\n",
    "    if output:\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        width, height = img.size\n",
    "        for i in range(0, _NUM_KEYPOINTS):\n",
    "            draw.ellipse(\n",
    "            xy=[\n",
    "                keypoints_with_scores[i][1] * width - 2, keypoints_with_scores[i][0] * height - 2,\n",
    "                keypoints_with_scores[i][1] * width + 2, keypoints_with_scores[i][0] * height + 2\n",
    "            ],\n",
    "            fill=(255, 0, 0))\n",
    "        img.save(output)\n",
    "        \n",
    "    return keypoints_with_scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keypoints_with_scores = get_result_from_image_with_model(\"input_image.jpeg\", interpreter)\n",
    "    print(type(keypoints_with_scores), keypoints_with_scores.shape, keypoints_with_scores, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339c05c-ae30-45fc-852b-7aef0aaaf42d",
   "metadata": {},
   "source": [
    "Can this code produce the effect of Step6? Check the speed in the last cell.<br>\n",
    "這個代碼能運行出Step6的效果嗎？在最後的單元格看看速度如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536d58df-9f29-4005-b90e-05bce5e45307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f25dd957824ae6a5546e293f8b2471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global ../modules/videoio/src/cap_gstreamer.cpp (961) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    }
   ],
   "source": [
    "repetition = squat = squatting = 0\n",
    "CONSECUTIVE_TH=3\n",
    "def frame_process(frame):\n",
    "    global repetition, squat, squatting\n",
    "    \n",
    "    # calculate and display angle\n",
    "    keypoints_with_scores = get_result_from_image_with_model(frame, interpreter)\n",
    "    \n",
    "    hip_angle = calculate_hip_joint_angle(keypoints_with_scores)\n",
    "    knee_angle = calculate_knee_joint_angle(keypoints_with_scores)\n",
    "\n",
    "    # check if confidence is qualified, if yes, proceed to judgement\n",
    "    if hip_angle is not None and knee_angle is not None:\n",
    "        # if capture continuous CONSECUTIVE_TH angles in squatting, change squat to 1\n",
    "        # if capture continuous CONSECUTIVE_TH angles in standing, change squat to 0 and repetition += 1\n",
    "        if hip_angle<125 and knee_angle<105:\n",
    "            if squat == 0:\n",
    "                squatting += 1\n",
    "            else:\n",
    "                squatting = CONSECUTIVE_TH\n",
    "        elif hip_angle>145 and knee_angle>125:\n",
    "            if squat == 1:\n",
    "                squatting -= 1\n",
    "            else:\n",
    "                squatting = 0\n",
    "        if squatting == 0 and squat == 1:\n",
    "            repetition += 1\n",
    "            squat = 0\n",
    "        elif squatting == CONSECUTIVE_TH and squat == 0:\n",
    "            squat = 1\n",
    "        text = f\"Reps: {repetition}  Knee: {int(knee_angle)}  Hip: {int(hip_angle)}\"\n",
    "    else:\n",
    "        text = f\"Reps: {repetition}  Knee: ?  Hip: ?\"\n",
    "    if squat:\n",
    "        text_color = (0,255,0)\n",
    "    else:\n",
    "        text_color = (128,192,64)\n",
    "        \n",
    "    putText(frame, text, text_color)\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Run\n",
    "# ================\n",
    "if __name__ == \"__main__\":\n",
    "    display(stopButton)\n",
    "    thread = threading.Thread(target=view, args=(stopButton, 0, 0, frame_process))\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49efd84-6e59-497c-9b59-d9e991d84cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average process time per frame is: 0.033530580030905234\n",
      "Average frame rate is: 29.823522261717425\n"
     ]
    }
   ],
   "source": [
    "average_time = sum(time_process) / len(time_process)\n",
    "\n",
    "print(f\"Average process time per frame is: { average_time }\")\n",
    "print(f\"Average frame rate is: { 1 / average_time }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5836d-458e-49fe-a2c4-7686b53097bf",
   "metadata": {},
   "source": [
    "### Squat: Two-player battle version.<br>深蹲：雙人對戰版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d7a184-7284-41e8-9153-ef8270fab29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f25dd957824ae6a5546e293f8b2471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "repetition1 = squat1 = squatting1 = repetition2 = squat2 = squatting2 = 0\n",
    "CONSECUTIVE_TH=3\n",
    "def frame_process(frame):    \n",
    "    global repetition1, squat1, squatting1, repetition2, squat2, squatting2\n",
    "    \n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    frame1 = (frame.transpose((1, 0, 2))[:frame_width//2]).transpose((1, 0, 2))\n",
    "    frame2 = (frame.transpose((1, 0, 2))[frame_width//2:]).transpose((1, 0, 2))\n",
    "    \n",
    "    # calculate and display angle\n",
    "    keypoints_with_scores1 = get_result_from_image_with_model(frame1, interpreter)\n",
    "    keypoints_with_scores2 = get_result_from_image_with_model(frame2, interpreter)\n",
    "    \n",
    "    hip_angle1 = calculate_hip_joint_angle(keypoints_with_scores1)\n",
    "    knee_angle1 = calculate_knee_joint_angle(keypoints_with_scores1)\n",
    "    hip_angle2 = calculate_hip_joint_angle(keypoints_with_scores2)\n",
    "    knee_angle2 = calculate_knee_joint_angle(keypoints_with_scores2)\n",
    "\n",
    "    # check if confidence is qualified, if yes, proceed to judgement\n",
    "    if hip_angle1 is not None and knee_angle1 is not None:\n",
    "        # if capture continuous CONSECUTIVE_TH angles in squatting, change squat to 1\n",
    "        # if capture continuous CONSECUTIVE_TH angles in standing, change squat to 0 and repetition += 1\n",
    "        if hip_angle1<125 and knee_angle1<105:\n",
    "            if squat1 == 0:\n",
    "                squatting1 += 1\n",
    "            else:\n",
    "                squatting1 = CONSECUTIVE_TH\n",
    "        elif hip_angle1>145 and knee_angle1>125:\n",
    "            if squat1 == 1:\n",
    "                squatting1 -= 1\n",
    "            else:\n",
    "                squatting1 = 0\n",
    "        if squatting1 == 0 and squat1 == 1:\n",
    "            repetition1 += 1\n",
    "            squat1 = 0\n",
    "        elif squatting1 == CONSECUTIVE_TH and squat1 == 0:\n",
    "            squat1 = 1\n",
    "        if squat1:\n",
    "            text_color1 = (0,255,0)\n",
    "            text1 = f\"=  Reps: {repetition1}   \"\n",
    "        else:\n",
    "            text_color1 = (64,240,160)\n",
    "            text1 = f\"+  Reps: {repetition1}   \"\n",
    "    else:\n",
    "        # +=1 or -=1 the value of squatting based on current status, clamped within [0, CONSECUTIVE_TH]\n",
    "        squatting1 = min(max((squatting1-1 if squat1 == 0 else squatting1+1), 0), CONSECUTIVE_TH)\n",
    "        text1 = f\"?  Reps: {repetition1}   \"\n",
    "        text_color1 = (128,128,128)\n",
    "    frame1 = cv2.resize(frame1, (int(200/frame_height*frame_width), 400))\n",
    "    putText(frame1, text1, text_color1)\n",
    "\n",
    "    if hip_angle2 is not None and knee_angle2 is not None:\n",
    "        # if capture continuous CONSECUTIVE_TH angles in squatting, change squat to 1\n",
    "        # if capture continuous CONSECUTIVE_TH angles in standing, change squat to 0 and repetition += 1\n",
    "        if hip_angle2<125 and knee_angle2<105:\n",
    "            if squat2 == 0:\n",
    "                squatting2 += 1\n",
    "            else:\n",
    "                squatting2 = CONSECUTIVE_TH\n",
    "        elif hip_angle2>145 and knee_angle2>125:\n",
    "            if squat2 == 1:\n",
    "                squatting2 -= 1\n",
    "            else:\n",
    "                squatting2 = 0\n",
    "        if squatting2 == 0 and squat2 == 1:\n",
    "            repetition2 += 1\n",
    "            squat2 = 0\n",
    "        elif squatting2 == CONSECUTIVE_TH and squat2 == 0:\n",
    "            squat2 = 1\n",
    "        if squat2:\n",
    "            text_color2 = (0,255,0)\n",
    "            text2 = f\"=  Reps: {repetition2}   \"\n",
    "        else:\n",
    "            text_color2 = (64,240,160)\n",
    "            text2 = f\"+  Reps: {repetition2}   \"\n",
    "    else:\n",
    "        # +=1 or -=1 the value of squatting based on current status, clamped within [0, CONSECUTIVE_TH]\n",
    "        squatting2 = min(max((squatting2-1 if squat2 == 0 else squatting2+1), 0), CONSECUTIVE_TH)\n",
    "        text2 = f\"?  Reps: {repetition2} \"\n",
    "        text_color2 = (128,128,128)\n",
    "    \n",
    "    frame2 = cv2.resize(frame2, (int(200/frame_height*frame_width), 400))\n",
    "    putText(frame2, text2, text_color2)\n",
    "\n",
    "    frame = np.concatenate((frame1, np.zeros((400, 10 ,3 )) , frame2  ) , axis=1)\n",
    "    \n",
    "    putText(frame, f\"Time: {int(time.time() - start_time)}s  FPS: \"\n",
    "        f\"{int(1/(sum(time_process[-5:])/len(time_process[-5:]))) if time_process else 'N/A'}\",\n",
    "        (160,224,160) , text_position=(50, 20))\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "    \n",
    "# Run\n",
    "# ================\n",
    "if __name__ == \"__main__\":\n",
    "    display(stopButton)\n",
    "    thread = threading.Thread(target=view, args=(stopButton, 0, 0, frame_process))\n",
    "    thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
